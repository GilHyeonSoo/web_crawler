import requests
import pandas as pd
import time
import os
import urllib.parse
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.common.action_chains import ActionChains
import re
import json

class FinalImageCrawler:
    def __init__(self):
        self.setup_driver()

    def setup_driver(self):
        options = webdriver.ChromeOptions()
        options.add_argument('--no-sandbox')
        options.add_argument('--disable-dev-shm-usage')
        options.add_argument('--disable-blink-features=AutomationControlled')
        options.add_experimental_option('excludeSwitches', ['enable-automation'])
        options.add_experimental_option('useAutomationExtension', False)
        options.add_argument('--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')
        self.driver = webdriver.Chrome(options=options)
        self.driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
        self.wait = WebDriverWait(self.driver, 15)

    def get_place_id_from_search(self, facility_name):
        try:
            encoded_name = urllib.parse.quote(facility_name)
            search_url = f"https://map.naver.com/p/search/{encoded_name}"
            print(f"ğŸ” ê²€ìƒ‰ URL: {search_url}")
            self.driver.get(search_url)
            time.sleep(2)
            current_url = self.driver.current_url
            place_id_match = re.search(r'/place/(\d+)', current_url)
            if place_id_match:
                place_id = place_id_match.group(1)
                print(f"âœ… Place ID ì°¾ìŒ: {place_id}")
                return place_id
            try:
                self.wait.until(EC.frame_to_be_available_and_switch_to_it((By.ID, "searchIframe")))
                time.sleep(1)
                list_items = self.driver.find_elements(By.CSS_SELECTOR, "li.VLTHu.OW9LQ")
                if list_items:
                    first_li = list_items[0]
                    # ë‚´ë¶€ aíƒœê·¸(í´ë¦­ìš©)
                    try:
                        link = first_li.find_element(By.CSS_SELECTOR, "a.place_bluelink")
                    except Exception:
                        # place_bluelinkê°€ ì—†ìœ¼ë©´ ê·¸ëƒ¥ ì²« ë²ˆì§¸ a íƒœê·¸ í´ë¦­
                        link = first_li.find_element(By.TAG_NAME, "a")
                    ActionChains(self.driver).move_to_element(link).click(link).perform()
                    time.sleep(2)
                    self.driver.switch_to.default_content()
                    self.wait.until(EC.frame_to_be_available_and_switch_to_it((By.ID, "entryIframe")))
                    time.sleep(1)
                    new_url = self.driver.current_url
                    place_id_match = re.search(r'place/(\d+)', new_url)
                    if place_id_match:
                        place_id = place_id_match.group(1)
                        print(f"âœ… ëª©ë¡ì—ì„œ í´ë¦­ í›„ Place ID íšë“: {place_id}")
                        return place_id
                    else:
                        print("âŒ entryIframeì—ì„œ place IDë¥¼ ë‹¤ì‹œ ëª» ì°¾ìŒ")
                else:
                    print("âŒ li.VLTHu.OW9LQ ëª©ë¡ ê²°ê³¼ê°€ ì—†ìŒ")
            except Exception as e3:
                print("âŒ ëª©ë¡ í´ë¦­/ì§„ì… ì—ëŸ¬:", e3)
            print("âŒ Place IDë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
            return None
        except Exception as e:
            print(f"ğŸ”´ Place ID ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            return None

    def extract_real_images_from_place(self, place_id):
        try:
            detail_urls = [
                f"https://m.place.naver.com/place/{place_id}/photo",
                f"https://m.place.naver.com/place/{place_id}/home",
                f"https://m.place.naver.com/place/{place_id}",
                f"https://place.naver.com/place/{place_id}/photo"
            ]
            for detail_url in detail_urls:
                print(f"ğŸ“¸ ìƒì„¸ í˜ì´ì§€ ì ‘ì† ì‹œë„: {detail_url}")
                self.driver.get(detail_url)
                time.sleep(2)
                self.analyze_page_content()
                image_url = self.find_real_photos()
                if image_url:
                    return image_url
            return None
        except Exception as e:
            print(f"ğŸ”´ ì‹¤ì œ ì‚¬ì§„ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            return None

    def analyze_page_content(self):
        try:
            page_source = self.driver.page_source
            photo_keywords = ['ì‚¬ì§„', 'photo', 'image', 'gallery', 'ë¦¬ë·°ì‚¬ì§„']
            found_keywords = [kw for kw in photo_keywords if kw in page_source]
            if found_keywords:
                print(f"âœ… í˜ì´ì§€ ë‚´ ì‚¬ì§„ ê´€ë ¨ í‚¤ì›Œë“œ ë°œê²¬: {found_keywords}")
            images = self.driver.find_elements(By.TAG_NAME, "img")
            print(f"ğŸ“¸ í˜ì´ì§€ ë‚´ ì´ë¯¸ì§€ íƒœê·¸ ìˆ˜: {len(images)}")
            for i, img in enumerate(images[:10]):
                src = img.get_attribute('src') or img.get_attribute('data-src') or img.get_attribute('data-original')
                if src:
                    print(f" ì´ë¯¸ì§€ {i+1}: {src[:100]}...")
                if self.is_real_facility_photo(src):
                    print(f" âœ… ì‹¤ì œ ì‹œì„¤ ì‚¬ì§„ìœ¼ë¡œ íŒë‹¨!")
            container_selectors = [
                "div.photo_area", "div._2y6cI", "div._section",
                "div.photo_list", "ul._3W4A1", "div._3uDEe",
                "div.Y5ZjY", "div.zDcC3", "div._3ocDE"
            ]
            for selector in container_selectors:
                elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                if elements:
                    print(f"âœ… ì»¨í…Œì´ë„ˆ ë°œê²¬: {selector} - {len(elements)}ê°œ")
            return True
        except Exception as e:
            print(f"ğŸ”´ í˜ì´ì§€ ë¶„ì„ ì˜¤ë¥˜: {e}")
            return False

    def find_real_photos(self):
        try:
            print("ğŸ”„ ì‹¤ì œ ì‚¬ì§„ ì°¾ê¸° ì‹œë„...")
            image_url = self.try_image_selectors()
            if image_url:
                return image_url
            image_url = self.try_data_attributes()
            if image_url:
                return image_url
            image_url = self.try_background_images()
            if image_url:
                return image_url
            image_url = self.try_javascript_extraction()
            if image_url:
                return image_url
            return None
        except Exception as e:
            print(f"ğŸ”´ ì‚¬ì§„ ì°¾ê¸° ì˜¤ë¥˜: {e}")
            return None

    def try_image_selectors(self):
        photo_selectors = [
            "img.Y6Ccc", "img._3y6cI", "img._3lmHh", "img._3ocDE", "img._27qo_",
            "img.place_thumb", "div.photo_area img", "div._2y6cI img", "div._section img", "div.photo_list img",
            "ul._3W4A1 img", "div._3uDEe img", "a._3lmHh img", "div.Y5ZjY img", "div.zDcC3 img",
            "img[src*='photo']", "img[src*='image']", "img[src*='upload']", "img[src*='thum']", "img[src*='blog']"
        ]
        for selector in photo_selectors:
            try:
                images = self.driver.find_elements(By.CSS_SELECTOR, selector)
                for img in images:
                    src = img.get_attribute('src')
                    if src and self.is_real_facility_photo(src):
                        print(f"âœ… ì„ íƒìë¡œ ì‹¤ì œ ì‚¬ì§„ ë°œê²¬: {selector}")
                        print(f" ì´ë¯¸ì§€ URL: {src[:100]}...")
                        return src
            except:
                continue
        return None

    def try_data_attributes(self):
        try:
            images_with_data = self.driver.find_elements(By.CSS_SELECTOR, "img[data-src]")
            for img in images_with_data:
                src = img.get_attribute('data-src')
                if src and self.is_real_facility_photo(src):
                    print(f"âœ… data-srcì—ì„œ ì‹¤ì œ ì‚¬ì§„ ë°œê²¬")
                    print(f" ì´ë¯¸ì§€ URL: {src[:100]}...")
                    return src
            images_with_original = self.driver.find_elements(By.CSS_SELECTOR, "img[data-original]")
            for img in images_with_original:
                src = img.get_attribute('data-original')
                if src and self.is_real_facility_photo(src):
                    print(f"âœ… data-originalì—ì„œ ì‹¤ì œ ì‚¬ì§„ ë°œê²¬")
                    print(f" ì´ë¯¸ì§€ URL: {src[:100]}...")
                    return src
            return None
        except:
            return None

    def try_background_images(self):
        try:
            elements_with_bg = self.driver.find_elements(By.CSS_SELECTOR, "[style*='background-image']")
            for element in elements_with_bg:
                style = element.get_attribute('style')
                bg_match = re.search(r'background-image:\s*url\(([^)]+)\)', style)
                if bg_match:
                    bg_url = bg_match.group(1).strip('"\'').replace('\\', '')
                    if bg_url and self.is_real_facility_photo(bg_url):
                        print(f"âœ… ë°°ê²½ ì´ë¯¸ì§€ì—ì„œ ì‹¤ì œ ì‚¬ì§„ ë°œê²¬")
                        print(f" ì´ë¯¸ì§€ URL: {bg_url[:100]}...")
                        return bg_url
            return None
        except:
            return None

    def try_javascript_extraction(self):
        try:
            js_script = """
var images = document.querySelectorAll('img');
var imageUrls = [];
for (var i = 0; i < images.length; i++) {
var src = images[i].src || images[i].getAttribute('data-src') || images[i].getAttribute('data-original');
if (src && src.startsWith('http')) { imageUrls.push(src); }
}
var elements = document.querySelectorAll('[style*="background-image"]');
for (var i = 0; i < elements.length; i++) {
var style = elements[i].getAttribute('style');
var match = style.match(/background-image:\\s*url\\(['\"]?([^'\")]+)['\"]?\\)/);
if (match && match[1]) { imageUrls.push(match[1]); }
}
return imageUrls;
"""
            all_image_urls = self.driver.execute_script(js_script)
            if all_image_urls:
                for img_url in all_image_urls:
                    if self.is_real_facility_photo(img_url):
                        print(f"âœ… JavaScriptë¡œ ì‹¤ì œ ì‚¬ì§„ ë°œê²¬")
                        print(f" ì´ë¯¸ì§€ URL: {img_url[:100]}...")
                        return img_url
            return None
        except:
            return None

    def is_real_facility_photo(self, img_url):
        if not img_url:
            return False
        img_url_lower = img_url.lower()
        ignore_patterns = [
            'npay', 'promo', 'banner', 'gstatic', 'al-icon', 'logo', 'icon', 'spi', 'ad','btn', 'button',
            'nav', 'menu', 'mobile', 'm_', 'pcweb', 'web', 'static/common', 'bar/', 'gnb/', 'svg', 'ico',
            'marker', 'category', 'around-category', 'selected-marker', 'mantle', 'data:image', 'transparent',
            'pixel', 'spacer', 'loading', 'placeholder'
        ]
        for pattern in ignore_patterns:
            if pattern in img_url_lower:
                return False
        photo_patterns = [
            'photo', 'image', 'img', 'upload', 'thum', 'blogfiles', 'postfiles', 'phinf', 'pstatic',
            'navercdn', 'placeimg', 'store', 'review', 'visit', 'contents'
        ]
        for pattern in photo_patterns:
            if pattern in img_url_lower:
                return True
        is_likely_photo = (
            any(ext in img_url_lower for ext in ['.jpg', '.jpeg', '.png', '.gif', '.webp']) and
            'http' in img_url_lower and len(img_url) > 50
        )
        return is_likely_photo

    def search_real_facility_images(self, facility_name):
        print(f"\nğŸ¯ ì‹œì„¤ ê²€ìƒ‰: {facility_name}")
        place_id = self.get_place_id_from_search(facility_name)
        if not place_id:
            print("âŒ Place IDë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
            return None
        image_url = self.extract_real_images_from_place(place_id)
        if image_url:
            print(f"ğŸŠ ìµœì¢… ì„±ê³µ: {image_url}")
        else:
            print("âŒ ì‹¤ì œ ì‹œì„¤ ì‚¬ì§„ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
        self.driver.save_screenshot(f"debug_{facility_name}_final.png")
        print(f"ğŸ“¸ ìµœì¢… ë””ë²„ê·¸ ìŠ¤í¬ë¦°ìƒ· ì €ì¥: debug_{facility_name}_final.png")
        return image_url

    def crawl_from_csv(self, csv_file_path, output_file="final_results.xlsx", start_index=0):
        try:
            print("ğŸ“ CSV íŒŒì¼ ì½ëŠ” ì¤‘...")
            df = pd.read_csv(csv_file_path, encoding='cp949')
            facilities = df.iloc[1:, 0].tolist()
            ids = df.iloc[1:, 3].tolist()
            facilities = [str(f) for f in facilities if pd.notna(f)]
            ids = [i for i in ids if pd.notna(i)]
            print(f"ğŸ“Š ì´ {len(facilities)}ê°œ ì‹œì„¤ ë°œê²¬")
            existing_results = []
            if os.path.exists(output_file):
                existing_df = pd.read_excel(output_file)
                existing_results = existing_df.to_dict('records')
                print(f"ğŸ“ ê¸°ì¡´ ê²°ê³¼ íŒŒì¼ ë°œê²¬: {len(existing_results)}ê°œ ì§„í–‰ë¨")
            results = existing_results
            for i, (facility, fac_id) in enumerate(zip(facilities[start_index:], ids[start_index:]), start_index+1):
                print(f"\n{'='*60}")
                print(f"ğŸ¥ ì²˜ë¦¬ ì¤‘ ({i}/{len(facilities)}): {facility} (ID: {fac_id})")
                if any(r['ì‹œì„¤ëª…'] == facility and r.get('ID', None) == fac_id for r in results):
                    print("â­ ì´ë¯¸ ì²˜ë¦¬ëœ ì‹œì„¤, ê±´ë„ˆëœ€")
                    continue
                image_url = self.search_real_facility_images(facility)
                results.append({
                    "ì‹œì„¤ëª…": facility,
                    "ì´ë¯¸ì§€_URL": image_url,
                    "ID": fac_id
                })
                if i % 10 == 0:
                    self.save_progress(results, output_file)
                    print(f"ğŸ’¾ ì¤‘ê°„ ì €ì¥ ì™„ë£Œ: {i}ê°œ ì²˜ë¦¬")
                time.sleep(2)
            self.save_progress(results, output_file)
            print(f"ğŸ‰ ëª¨ë“  ì²˜ë¦¬ ì™„ë£Œ! ì´ {len(results)}ê°œ ì‹œì„¤ ì²˜ë¦¬ë¨")
            successful = sum(1 for r in results if r['ì´ë¯¸ì§€_URL'] is not None)
            print(f"ğŸ“Š ìµœì¢… ì„±ê³µë¥ : {successful}/{len(results)} ({successful/len(results)*100:.1f}%)")
            return results
        except Exception as e:
            print(f"ğŸ”´ CSV ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
            return []

    def save_progress(self, results, output_file):
        df = pd.DataFrame(results)
        df.to_excel(output_file, index=False)

    def close(self):
        if self.driver:
            self.driver.quit()

def main():
    crawler = FinalImageCrawler()
    try:
        csv_file = "Animallo-vb1.csv"
        if not os.path.exists(csv_file):
            print(f"âŒ CSV íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {csv_file}")
            return
        start_index = 0
        results = crawler.crawl_from_csv(
            csv_file_path=csv_file,
            output_file="final_facility_images.xlsx",
            start_index=start_index
        )
        print("\nğŸŠ í”„ë¡œê·¸ë¨ ì™„ë£Œ!")
    except Exception as e:
        print(f"ğŸ”´ í”„ë¡œê·¸ë¨ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
    finally:
        crawler.close()

if __name__ == "__main__":
    main()
