import requests
import pandas as pd
import time
import os
import urllib.parse
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.common.action_chains import ActionChains
import re
import json

class FinalImageCrawler:
    def __init__(self):
        self.setup_driver()
    
    def setup_driver(self):
        """ë“œë¼ì´ë²„ ì„¤ì •"""
        options = webdriver.ChromeOptions()
        options.add_argument('--no-sandbox')
        options.add_argument('--disable-dev-shm-usage')
        options.add_argument('--disable-blink-features=AutomationControlled')
        options.add_experimental_option('excludeSwitches', ['enable-automation'])
        options.add_experimental_option('useAutomationExtension', False)
        options.add_argument('--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')
        
        self.driver = webdriver.Chrome(options=options)
        self.driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
        self.wait = WebDriverWait(self.driver, 15)
    
    def get_place_id_from_search(self, facility_name):
        """ê²€ìƒ‰ ê²°ê³¼ì—ì„œ place ID ì¶”ì¶œ"""
        try:
            encoded_name = urllib.parse.quote(facility_name)
            search_url = f"https://map.naver.com/p/search/{encoded_name}"
            print(f"ğŸ” ê²€ìƒ‰ URL: {search_url}")
            
            self.driver.get(search_url)
            time.sleep(5)
            
            # í˜„ì¬ URLì—ì„œ place ID ì¶”ì¶œ ì‹œë„
            current_url = self.driver.current_url
            place_id_match = re.search(r'/place/(\d+)', current_url)
            
            if place_id_match:
                place_id = place_id_match.group(1)
                print(f"âœ… Place ID ì°¾ìŒ: {place_id}")
                return place_id
            
            print("âŒ Place IDë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
            return None
            
        except Exception as e:
            print(f"ğŸ”´ Place ID ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            return None
    
    def extract_real_images_from_place(self, place_id):
        """Place ìƒì„¸ í˜ì´ì§€ì—ì„œ ì‹¤ì œ ì‹œì„¤ ì‚¬ì§„ ì¶”ì¶œ - ê°•í™”ëœ ë²„ì „"""
        try:
            # ìƒì„¸ í˜ì´ì§€ URL (ì—¬ëŸ¬ ê°€ì§€ URL ì‹œë„)
            detail_urls = [
                f"https://m.place.naver.com/place/{place_id}/photo",
                f"https://m.place.naver.com/place/{place_id}/home",
                f"https://m.place.naver.com/place/{place_id}",
                f"https://place.naver.com/place/{place_id}/photo"
            ]
            
            for detail_url in detail_urls:
                print(f"ğŸ“¸ ìƒì„¸ í˜ì´ì§€ ì ‘ì† ì‹œë„: {detail_url}")
                self.driver.get(detail_url)
                time.sleep(5)
                
                # í˜ì´ì§€ ë¶„ì„
                self.analyze_page_content()
                
                # ì‹¤ì œ ì‚¬ì§„ ì¶”ì¶œ ì‹œë„
                image_url = self.find_real_photos()
                if image_url:
                    return image_url
            
            return None
            
        except Exception as e:
            print(f"ğŸ”´ ì‹¤ì œ ì‚¬ì§„ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            return None
    
    def analyze_page_content(self):
        """í˜ì´ì§€ ë‚´ìš© ë¶„ì„"""
        try:
            # í˜ì´ì§€ ì†ŒìŠ¤ ë¶„ì„
            page_source = self.driver.page_source
            
            # ì‚¬ì§„ ê´€ë ¨ í‚¤ì›Œë“œ í™•ì¸
            photo_keywords = ['ì‚¬ì§„', 'photo', 'image', 'gallery', 'ë¦¬ë·°ì‚¬ì§„']
            found_keywords = [kw for kw in photo_keywords if kw in page_source]
            if found_keywords:
                print(f"âœ… í˜ì´ì§€ ë‚´ ì‚¬ì§„ ê´€ë ¨ í‚¤ì›Œë“œ ë°œê²¬: {found_keywords}")
            
            # ëª¨ë“  ì´ë¯¸ì§€ íƒœê·¸ ë¶„ì„
            images = self.driver.find_elements(By.TAG_NAME, "img")
            print(f"ğŸ“¸ í˜ì´ì§€ ë‚´ ì´ë¯¸ì§€ íƒœê·¸ ìˆ˜: {len(images)}")
            
            # ì´ë¯¸ì§€ URLë“¤ ì¶œë ¥ (ìƒìœ„ 10ê°œ)
            for i, img in enumerate(images[:10]):
                src = img.get_attribute('src') or img.get_attribute('data-src') or img.get_attribute('data-original')
                if src:
                    print(f"  ì´ë¯¸ì§€ {i+1}: {src[:100]}...")
                    # ì‹¤ì œ ì‚¬ì§„ì¸ì§€ í™•ì¸
                    if self.is_real_facility_photo(src):
                        print(f"    âœ… ì‹¤ì œ ì‹œì„¤ ì‚¬ì§„ìœ¼ë¡œ íŒë‹¨!")
            
            # í˜ì´ì§€ êµ¬ì¡° ë¶„ì„
            container_selectors = [
                "div.photo_area", "div._2y6cI", "div._section", 
                "div.photo_list", "ul._3W4A1", "div._3uDEe",
                "div.Y5ZjY", "div.zDcC3", "div._3ocDE"
            ]
            
            for selector in container_selectors:
                elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                if elements:
                    print(f"âœ… ì»¨í…Œì´ë„ˆ ë°œê²¬: {selector} - {len(elements)}ê°œ")
            
            return True
            
        except Exception as e:
            print(f"ğŸ”´ í˜ì´ì§€ ë¶„ì„ ì˜¤ë¥˜: {e}")
            return False
    
    def find_real_photos(self):
        """ì‹¤ì œ ì‚¬ì§„ ì°¾ê¸° - ë‹¤ì–‘í•œ ë°©ë²• ì‹œë„"""
        try:
            print("ğŸ”„ ì‹¤ì œ ì‚¬ì§„ ì°¾ê¸° ì‹œë„...")
            
            # ë°©ë²• 1: ë‹¤ì–‘í•œ ì´ë¯¸ì§€ ì„ íƒì ì‹œë„
            image_url = self.try_image_selectors()
            if image_url:
                return image_url
            
            # ë°©ë²• 2: data-src ì†ì„±ì—ì„œ ì°¾ê¸° (lazy loading)
            image_url = self.try_data_attributes()
            if image_url:
                return image_url
            
            # ë°©ë²• 3: ë°°ê²½ ì´ë¯¸ì§€ì—ì„œ ì°¾ê¸°
            image_url = self.try_background_images()
            if image_url:
                return image_url
            
            # ë°©ë²• 4: JavaScriptë¡œ ìˆ¨ê²¨ì§„ ì´ë¯¸ì§€ ì°¾ê¸°
            image_url = self.try_javascript_extraction()
            if image_url:
                return image_url
            
            return None
            
        except Exception as e:
            print(f"ğŸ”´ ì‚¬ì§„ ì°¾ê¸° ì˜¤ë¥˜: {e}")
            return None
    
    def try_image_selectors(self):
        """ë‹¤ì–‘í•œ ì´ë¯¸ì§€ ì„ íƒìë¡œ ì‚¬ì§„ ì°¾ê¸°"""
        photo_selectors = [
            # ë„¤ì´ë²„ í”Œë ˆì´ìŠ¤ ê³µì‹ ì„ íƒìë“¤
            "img.Y6Ccc",  # ì‚¬ì§„ ì´ë¯¸ì§€
            "img._3y6cI", 
            "img._3lmHh",
            "img._3ocDE",
            "img._27qo_",
            "img.place_thumb",
            "div.photo_area img",
            "div._2y6cI img",
            "div._section img",
            "div.photo_list img",
            "ul._3W4A1 img",
            "div._3uDEe img",
            "a._3lmHh img",
            "div.Y5ZjY img",
            "div.zDcC3 img",
            # ì¼ë°˜ì ì¸ ì‚¬ì§„ ì„ íƒì
            "img[src*='photo']",
            "img[src*='image']",
            "img[src*='upload']",
            "img[src*='thum']",
            "img[src*='blog']"
        ]
        
        for selector in photo_selectors:
            try:
                images = self.driver.find_elements(By.CSS_SELECTOR, selector)
                for img in images:
                    src = img.get_attribute('src')
                    if src and self.is_real_facility_photo(src):
                        print(f"âœ… ì„ íƒìë¡œ ì‹¤ì œ ì‚¬ì§„ ë°œê²¬: {selector}")
                        print(f"   ì´ë¯¸ì§€ URL: {src[:100]}...")
                        return src
            except:
                continue
        
        return None
    
    def try_data_attributes(self):
        """data-src ë“± ë°ì´í„° ì†ì„±ì—ì„œ ì´ë¯¸ì§€ ì°¾ê¸°"""
        try:
            # data-src ì†ì„±ì´ ìˆëŠ” ì´ë¯¸ì§€ ì°¾ê¸°
            images_with_data = self.driver.find_elements(By.CSS_SELECTOR, "img[data-src]")
            for img in images_with_data:
                src = img.get_attribute('data-src')
                if src and self.is_real_facility_photo(src):
                    print(f"âœ… data-srcì—ì„œ ì‹¤ì œ ì‚¬ì§„ ë°œê²¬")
                    print(f"   ì´ë¯¸ì§€ URL: {src[:100]}...")
                    return src
            
            # data-original ì†ì„±ë„ í™•ì¸
            images_with_original = self.driver.find_elements(By.CSS_SELECTOR, "img[data-original]")
            for img in images_with_original:
                src = img.get_attribute('data-original')
                if src and self.is_real_facility_photo(src):
                    print(f"âœ… data-originalì—ì„œ ì‹¤ì œ ì‚¬ì§„ ë°œê²¬")
                    print(f"   ì´ë¯¸ì§€ URL: {src[:100]}...")
                    return src
            
            return None
        except:
            return None
    
    def try_background_images(self):
        """CSS ë°°ê²½ ì´ë¯¸ì§€ì—ì„œ ì°¾ê¸°"""
        try:
            # ë°°ê²½ ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•˜ëŠ” ìš”ì†Œ ì°¾ê¸°
            elements_with_bg = self.driver.find_elements(By.CSS_SELECTOR, "[style*='background-image']")
            for element in elements_with_bg:
                style = element.get_attribute('style')
                bg_match = re.search(r'background-image:\s*url\(([^)]+)\)', style)
                if bg_match:
                    bg_url = bg_match.group(1).strip('"\'').replace('\\', '')
                    if bg_url and self.is_real_facility_photo(bg_url):
                        print(f"âœ… ë°°ê²½ ì´ë¯¸ì§€ì—ì„œ ì‹¤ì œ ì‚¬ì§„ ë°œê²¬")
                        print(f"   ì´ë¯¸ì§€ URL: {bg_url[:100]}...")
                        return bg_url
            return None
        except:
            return None
    
    def try_javascript_extraction(self):
        """JavaScriptë¡œ ì´ë¯¸ì§€ URL ì¶”ì¶œ"""
        try:
            # í˜ì´ì§€ì˜ ëª¨ë“  ì´ë¯¸ì§€ URLì„ JavaScriptë¡œ ìˆ˜ì§‘
            js_script = """
            var images = document.querySelectorAll('img');
            var imageUrls = [];
            for (var i = 0; i < images.length; i++) {
                var src = images[i].src || images[i].getAttribute('data-src') || images[i].getAttribute('data-original');
                if (src && src.startsWith('http')) {
                    imageUrls.push(src);
                }
            }
            
            // ë°°ê²½ ì´ë¯¸ì§€ë„ ìˆ˜ì§‘
            var elements = document.querySelectorAll('[style*="background-image"]');
            for (var i = 0; i < elements.length; i++) {
                var style = elements[i].getAttribute('style');
                var match = style.match(/background-image:\\s*url\\(['"]?([^'")]+)['"]?\\)/);
                if (match && match[1]) {
                    imageUrls.push(match[1]);
                }
            }
            return imageUrls;
            """
            
            all_image_urls = self.driver.execute_script(js_script)
            if all_image_urls:
                for img_url in all_image_urls:
                    if self.is_real_facility_photo(img_url):
                        print(f"âœ… JavaScriptë¡œ ì‹¤ì œ ì‚¬ì§„ ë°œê²¬")
                        print(f"   ì´ë¯¸ì§€ URL: {img_url[:100]}...")
                        return img_url
            
            return None
        except:
            return None
    
    def is_real_facility_photo(self, img_url):
        """ì‹¤ì œ ì‹œì„¤ ì‚¬ì§„ì¸ì§€ í™•ì¸ - ê°•í™”ëœ í•„í„°ë§"""
        if not img_url:
            return False
            
        img_url_lower = img_url.lower()
        
        # ë¬´ì‹œí•  íŒ¨í„´ (ì•„ì´ì½˜, ë¡œê³ , ë§ˆì»¤ ë“±)
        ignore_patterns = [
            'npay', 'promo', 'banner',
            'gstatic', 'al-icon',
            'logo', 'icon',
            'spi', 'ad',
            'btn', 'button',
            'nav', 'menu',
            'mobile', 'm_',
            'pcweb', 'web',
            'static/common',
            'bar/', 'gnb/',
            'svg', 'ico',
            'marker',  # ì§€ë„ ë§ˆì»¤
            'category',  # ì¹´í…Œê³ ë¦¬ ì•„ì´ì½˜
            'around-category',  # ì£¼ë³€ ì¹´í…Œê³ ë¦¬
            'selected-marker',  # ì„ íƒëœ ë§ˆì»¤
            'mantle',  # ë§¨í‹€
            'data:image',  # base64 ë°ì´í„°
            'transparent',  # íˆ¬ëª… ì´ë¯¸ì§€
            'pixel',  # í”½ì…€ ì´ë¯¸ì§€
            'spacer',  # ì—¬ë°± ì´ë¯¸ì§€
            'loading',  # ë¡œë”© ì´ë¯¸ì§€
            'placeholder'  # í”Œë ˆì´ìŠ¤í™€ë”
        ]
        
        for pattern in ignore_patterns:
            if pattern in img_url_lower:
                return False
        
        # ì‹¤ì œ ì‚¬ì§„ íŒ¨í„´ (ê°•í™”ë¨)
        photo_patterns = [
            'photo', 'image', 'img',
            'upload', 'thum',
            'blogfiles', 'postfiles',
            'phinf', 'pstatic',
            'navercdn',  # ë„¤ì´ë²„ CDN
            'placeimg',  # ì¥ì†Œ ì´ë¯¸ì§€
            'store',  # ë§¤ì¥ ì´ë¯¸ì§€
            'review',  # ë¦¬ë·° ì´ë¯¸ì§€
            'visit',  # ë°©ë¬¸ ì´ë¯¸ì§€
            'contents'  # ì½˜í…ì¸  ì´ë¯¸ì§€
        ]
        
        for pattern in photo_patterns:
            if pattern in img_url_lower:
                return True
        
        # ì‹¤ì œ ì‚¬ì§„ì˜ ì¼ë°˜ì ì¸ íŠ¹ì„±
        is_likely_photo = (
            any(ext in img_url_lower for ext in ['.jpg', '.jpeg', '.png', '.gif', '.webp']) and
            'http' in img_url_lower and
            len(img_url) > 50  # ì‹¤ì œ ì‚¬ì§„ URLì€ ì¼ë°˜ì ìœ¼ë¡œ ê¸¸ë‹¤
        )
        
        return is_likely_photo
    
    def search_real_facility_images(self, facility_name):
        """ì‹¤ì œ ì‹œì„¤ ì‚¬ì§„ ê²€ìƒ‰ ë©”ì¸ í•¨ìˆ˜"""
        print(f"\nğŸ¯ ì‹œì„¤ ê²€ìƒ‰: {facility_name}")
        
        # 1. Place ID ì¶”ì¶œ
        place_id = self.get_place_id_from_search(facility_name)
        if not place_id:
            print("âŒ Place IDë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
            return None
        
        # 2. ì‹¤ì œ ì‚¬ì§„ ì¶”ì¶œ
        image_url = self.extract_real_images_from_place(place_id)
        
        if image_url:
            print(f"ğŸŠ ìµœì¢… ì„±ê³µ: {image_url}")
        else:
            print("âŒ ì‹¤ì œ ì‹œì„¤ ì‚¬ì§„ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
            # ë””ë²„ê¹…ì„ ìœ„í•œ ìŠ¤í¬ë¦°ìƒ·
            self.driver.save_screenshot(f"debug_{facility_name}_final.png")
            print(f"ğŸ“¸ ìµœì¢… ë””ë²„ê·¸ ìŠ¤í¬ë¦°ìƒ· ì €ì¥: debug_{facility_name}_final.png")
        
        return image_url

    def crawl_from_csv(self, csv_file_path, output_file="final_results.xlsx", start_index=0):
        """CSV íŒŒì¼ì—ì„œ ì‹œì„¤ëª…ì„ ì½ì–´ ì´ë¯¸ì§€ ìˆ˜ì§‘"""
        try:
            # CSV íŒŒì¼ ì½ê¸°
            print("ğŸ“ CSV íŒŒì¼ ì½ëŠ” ì¤‘...")
            df = pd.read_csv(csv_file_path, encoding='cp949')
            
            # Aì—´(ì‹œì„¤ëª…) ì¶”ì¶œ - 2í–‰ë¶€í„° (1í–‰ì€ í—¤ë”ë¼ê³  ê°€ì •)
            facilities = df.iloc[1:, 0].tolist()  # Aì—´ì€ 0ë²ˆ ì¸ë±ìŠ¤
            facilities = [str(f) for f in facilities if pd.notna(f)]
            
            print(f"ğŸ“Š ì´ {len(facilities)}ê°œ ì‹œì„¤ ë°œê²¬")
            
            # ê¸°ì¡´ ê²°ê³¼ íŒŒì¼ì´ ìˆìœ¼ë©´ ì´ì–´ì„œ ì§„í–‰
            existing_results = []
            if os.path.exists(output_file):
                existing_df = pd.read_excel(output_file)
                existing_results = existing_df.to_dict('records')
                print(f"ğŸ“ ê¸°ì¡´ ê²°ê³¼ íŒŒì¼ ë°œê²¬: {len(existing_results)}ê°œ ì§„í–‰ë¨")
            
            results = existing_results
            
            for i, facility in enumerate(facilities[start_index:], start_index + 1):
                print(f"\n{'='*60}")
                print(f"ğŸ¥ ì²˜ë¦¬ ì¤‘ ({i}/{len(facilities)}): {facility}")
                
                # ì´ë¯¸ ì²˜ë¦¬ëœ ì‹œì„¤ì€ ê±´ë„ˆë›°ê¸°
                if any(r['ì‹œì„¤ëª…'] == facility for r in results):
                    print("â­ï¸ ì´ë¯¸ ì²˜ë¦¬ëœ ì‹œì„¤, ê±´ë„ˆëœ€")
                    continue
                
                image_url = self.search_real_facility_images(facility)
                
                results.append({
                    "ì‹œì„¤ëª…": facility, 
                    "ì´ë¯¸ì§€_URL": image_url
                })
                
                # 10ê°œë§ˆë‹¤ ì¤‘ê°„ ì €ì¥
                if i % 10 == 0:
                    self.save_progress(results, output_file)
                    print(f"ğŸ’¾ ì¤‘ê°„ ì €ì¥ ì™„ë£Œ: {i}ê°œ ì²˜ë¦¬")
                
                # ìš”ì²­ ê°„ê²©
                time.sleep(2)
            
            # ìµœì¢… ì €ì¥
            self.save_progress(results, output_file)
            print(f"ğŸ‰ ëª¨ë“  ì²˜ë¦¬ ì™„ë£Œ! ì´ {len(results)}ê°œ ì‹œì„¤ ì²˜ë¦¬ë¨")
            
            # í†µê³„ ì¶œë ¥
            successful = sum(1 for r in results if r['ì´ë¯¸ì§€_URL'] is not None)
            print(f"ğŸ“Š ìµœì¢… ì„±ê³µë¥ : {successful}/{len(results)} ({successful/len(results)*100:.1f}%)")
            
            return results
            
        except Exception as e:
            print(f"ğŸ”´ CSV ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
            return []

    def save_progress(self, results, output_file):
        """ì§„í–‰ ìƒí™© ì €ì¥"""
        df = pd.DataFrame(results)
        df.to_excel(output_file, index=False)
    
    def close(self):
        """ë“œë¼ì´ë²„ ì¢…ë£Œ"""
        if self.driver:
            self.driver.quit()

# ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
def main():
    crawler = FinalImageCrawler()
    
    try:
        # CSV íŒŒì¼ ê²½ë¡œ
        csv_file = "Animallo-vb1.csv"  # ì‹¤ì œ íŒŒì¼ëª…ìœ¼ë¡œ ë³€ê²½í•´ì£¼ì„¸ìš”
        
        if not os.path.exists(csv_file):
            print(f"âŒ CSV íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {csv_file}")
            return
        
        # ì‹œì‘ ì¸ë±ìŠ¤ (ì¤‘ê°„ì— ëŠê²¼ì„ ê²½ìš° ì´ì–´ì„œ ì‹œì‘)
        start_index = 0
        
        # ì „ì²´ í¬ë¡¤ë§ ì‹¤í–‰
        results = crawler.crawl_from_csv(
            csv_file_path=csv_file,
            output_file="final_facility_images.xlsx",
            start_index=start_index
        )
        
        print("\nğŸŠ í”„ë¡œê·¸ë¨ ì™„ë£Œ!")
        
    except Exception as e:
        print(f"ğŸ”´ í”„ë¡œê·¸ë¨ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
    
    finally:
        crawler.close()

if __name__ == "__main__":
    main()